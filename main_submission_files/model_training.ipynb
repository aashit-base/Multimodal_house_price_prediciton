{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNy-hXIHQLSh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torchvision.models import Inception_V3_Weights\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFyCHpsudUkF",
        "outputId": "d0fa911f-920b-4925-c5bd-b03da21c3b49"
      },
      "outputs": [],
      "source": [
        "#Device change\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n1iSjTMegwp",
        "outputId": "88f52a17-4d9a-4b48-c835-c2738b647c73"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")\n",
        "# useful if all data is on a drive or working on google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk1et42tIDYq"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "collapsed": true,
        "id": "XUrdkVHUQvC3",
        "outputId": "0d807b18-8e45-4bc2-b948-b319748e3e4e"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('C:\\\\Users\\\\Aashit\\\\OneDrive\\\\Desktop\\\\Coding_stuff\\\\PROJECTS\\\\real-estate-multimodal\\\\train_preprocessed.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cu8gAKGfQ8l7",
        "outputId": "7eeb0268-5c45-4550-c922-0e3cb101939d"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDHmeXQfWS5P"
      },
      "source": [
        "## FIRST MODEL (Based on tabular only data)\n",
        "- comparing various ML algorithms performance on the dataset to see which fits best and gives more accurate results.\n",
        "- The target variable is log-transformed house price (price_log) to reduce skewness and improve regression stability. Continuous numerical features are standardized, while ordinal and binary variables are left unscaled to preserve their semantic meaning.\n",
        "- Multiple regression algorithms (Linear, Ridge, Lasso, Random Forest, and XGBoost) are evaluated using R² score and RMSE on a validation set. The best-performing tabular model serves both as a performance baseline and as a fallback model for cases where satellite imagery is unavailable during inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFwVlz9yTBpj"
      },
      "outputs": [],
      "source": [
        "DROP_COLS = [\n",
        "    \"id\", \"date\",\n",
        "    \"price\",\n",
        "    \"lat\", \"long\",\n",
        "    \"yr_built\", \"yr_renovated\"\n",
        "]\n",
        "#dropping redundant and unuseful columns for now\n",
        "target = \"price_log\"\n",
        "df_model = df.drop(columns=[c for c in DROP_COLS if c in df.columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S6BLRLwVCw3"
      },
      "outputs": [],
      "source": [
        "X = df_model.drop(columns=[target])\n",
        "y = df_model[target]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r7UEyXKVNKJ"
      },
      "outputs": [],
      "source": [
        "# scale_cols = [\"sqft_living\", \"sqft_lot\", \"sqft_basement\",\"sqft_living15\", \"sqft_lot15\", \"house_age\"]\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
        "# X_val[scale_cols] = scaler.transform(X_val[scale_cols])\n",
        "\n",
        "# trying scaling all the features (even ordinals)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_dgrskzXGVu"
      },
      "source": [
        "### Trying out linear models first\n",
        "- Regularization parameters for linear models were initially set to standard values for baseline comparison and later tuned using cross-validation when necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "collapsed": true,
        "id": "IUQzoLArYBa4",
        "outputId": "fd1d3b73-df22-401e-f894-2ed7e1a0060e"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "models = {\n",
        "    \"Linear\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(alpha=1.0),\n",
        "    \"Lasso\": Lasso(alpha=0.001)\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "\n",
        "    r2 = r2_score(y_val, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "\n",
        "    results.append({\"Model\": name,\"R2\": r2,\"RMSE\": rmse})\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values(\"R2\", ascending=False)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxHlazUkZDrF"
      },
      "source": [
        "- The strong performance of the linear models (R² ≈ 0.82) indicates that the preprocessing and feature engineering steps were effective. Log-transforming the target reduced skewness, while engineered features such as house age, renovation status, and neighborhood-level variables improved signal quality. Proper handling of continuous versus ordinal features further contributed to a well-conditioned feature space, resulting in stable and consistent linear model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWnvHbdyZWEI"
      },
      "source": [
        "### Next Tree-Based Models\n",
        "\n",
        "After establishing strong linear baselines, we now evaluate tree-based models that can capture non-linear interactions between housing features. These models help assess whether additional structural complexity improves performance over linear assumptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v57yVdmXZGA5",
        "outputId": "35558aad-8904-4e58-e367-fb1b80e27881"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators=300,max_depth=20,min_samples_split=10,min_samples_leaf=5,\n",
        "                           max_features=\"sqrt\", random_state=42,n_jobs=-1)\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred = rf.predict(X_val)\n",
        "r2 = r2_score(y_val,y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val,y_pred))\n",
        "\n",
        "train_preds_rf = rf.predict(X_train)\n",
        "train_r2_rf = r2_score(y_train, train_preds_rf)\n",
        "train_rmse_rf = np.sqrt(mean_squared_error(y_train,train_preds_rf))\n",
        "print(f\"R2: {r2}, RMSE: {rmse}\")\n",
        "print(f\"Random forest Train R2: {train_r2_rf} , RMSE: {train_rmse_rf}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZbvqs02avuC"
      },
      "source": [
        "- The Random Forest model outperforms all linear baselines, achieving an R² of 0.847 and a lower RMSE. This small improvement indicates the presence of some meaningful non-linear interactions among housing features, while still relying solely on tabular data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMiA2H1xa0FV",
        "outputId": "3eaf590a-a4f1-4053-f31b-fc43a6d98d8f"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=600,learning_rate=0.05, max_depth=6, subsample=0.8,\n",
        "                             colsample_bytree=0.8, reg_alpha=0.0, reg_lambda=1.0,\n",
        "                             random_state=42,n_jobs=-1)\n",
        "xgb_model.fit(X_train,y_train)\n",
        "preds = xgb_model.predict(X_val)\n",
        "r2_xgb = r2_score(y_val,preds)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_val,preds))\n",
        "\n",
        "train_preds_xgb = xgb_model.predict(X_train)\n",
        "train_r2_xgb = r2_score(y_train, train_preds_xgb)\n",
        "train_rmse_xgb = np.sqrt(mean_squared_error(y_train,train_preds_xgb))\n",
        "\n",
        "print(f\"XGBoost Train R2: {train_r2_xgb} , RMSE: {train_rmse_xgb}\")\n",
        "print(f\"R2: {r2_xgb}, RMSE: {rmse_xgb}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# K-Fold setup to test mean R2 for best ML model\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_scores = []\n",
        "rmse_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X), 1):\n",
        "    X_tr, X_vl = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_tr, y_vl = y.iloc[train_idx], y.iloc[val_idx]\n",
        "    \n",
        "    # Scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_tr_scaled = scaler.fit_transform(X_tr)\n",
        "    X_vl_scaled = scaler.transform(X_vl)\n",
        "    \n",
        "    model = xgb.XGBRegressor(n_estimators=600, learning_rate=0.05, max_depth=6,\n",
        "                             subsample=0.8, colsample_bytree=0.8,\n",
        "                             reg_alpha=0.0, reg_lambda=1.0,\n",
        "                             random_state=42, n_jobs=-1)\n",
        "    \n",
        "    model.fit(X_tr_scaled, y_tr)\n",
        "    preds = model.predict(X_vl_scaled)\n",
        "    \n",
        "    r2 = r2_score(y_vl, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_vl, preds))\n",
        "    \n",
        "    r2_scores.append(r2)\n",
        "    rmse_scores.append(rmse)\n",
        "    print(f\"Fold {fold}: R2={r2:.4f}, RMSE={rmse:.2f}\")\n",
        "\n",
        "print(f\"\\nMean R2: {np.mean(r2_scores):.4f} +/- {np.std(r2_scores):.4f}\")\n",
        "print(f\"Mean RMSE: {np.mean(rmse_scores):.2f} +/- {np.std(rmse_scores):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsqNAjsmcQ_u"
      },
      "source": [
        "- XGBoost achieves the best performance among tabular-only models with an R² of 0.86, marginally improving over Random Forest. The modest gain suggests diminishing returns from increased model complexity, establishing a strong and stable benchmark for evaluating multimodal approaches.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3BfOU3zcpwc"
      },
      "source": [
        "## Second Model: Tabular Neural Network\n",
        "- In this stage, we train a neural network using tabular features only to evaluate whether a learned, non-linear representation can improve performance over traditional machine learning models. This experiment serves as a transitional step between classical tabular models and the final multimodal architecture, helping isolate the effect of neural networks on structured data before introducing satellite imagery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0l3s3SQdZoN"
      },
      "outputs": [],
      "source": [
        "# Convert pandas DataFrames/Series to NumPy arrays before creating PyTorch tensors\n",
        "\n",
        "X_train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_val_tensor   = torch.from_numpy(X_val.astype(np.float32))\n",
        "\n",
        "y_train_tensor = torch.from_numpy(y_train.to_numpy().astype(np.float32))\n",
        "y_val_tensor   = torch.from_numpy(y_val.to_numpy().astype(np.float32))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9vBp5oGhHhL",
        "outputId": "86441a51-ef6d-4173-987e-3352a092be62"
      },
      "outputs": [],
      "source": [
        "X_train_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gYdIMRJhLbO",
        "outputId": "b19757bb-382c-4cef-f087-57a873e25c5e"
      },
      "outputs": [],
      "source": [
        "y_train_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV4neRmchOtv"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, labels):\n",
        "\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    return self.features[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2an04dDhmF4"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = CustomDataset(X_val_tensor, y_val_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgSXS9LJiKb7"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSHVTjQXjVea",
        "outputId": "a924f44a-60df-40cc-83ff-72ba4d8378fa"
      },
      "outputs": [],
      "source": [
        "#number of batches\n",
        "print(len(train_loader), len(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIjVvYqtoPI_"
      },
      "outputs": [],
      "source": [
        "class TabularOnlyNN(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super(TabularOnlyNN, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128,64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(64,1)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APOouI8AujzD"
      },
      "outputs": [],
      "source": [
        "# making model and moving to gpu\n",
        "tabularmodel = TabularOnlyNN(X_train.shape[1]).to(device)\n",
        "criterion = nn.MSELoss() #loss function\n",
        "\n",
        "optimizer_one = torch.optim.Adam( #optimizer for updating\n",
        "    tabularmodel.parameters(),\n",
        "    lr=1e-3,\n",
        "    betas=(0.9, 0.999),\n",
        "    weight_decay=1e-5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BkCE1fLXu83K",
        "outputId": "a93d6c8a-0476-40ed-c4b7-3817517a20bd"
      },
      "outputs": [],
      "source": [
        "epochs = 70\n",
        "for epoch in range(epochs):\n",
        "  tabularmodel.train()\n",
        "  total_epoch_loss = 0\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device).view(-1,1)\n",
        "    # pushing them into gpu\n",
        "\n",
        "    outputs = tabularmodel(batch_features)\n",
        "    optimizer_one.zero_grad()\n",
        "    loss = criterion(outputs, batch_labels)\n",
        "    loss.backward()\n",
        "    optimizer_one.step()\n",
        "    total_epoch_loss = total_epoch_loss + loss.item()\n",
        "  avg_loss = total_epoch_loss/len(train_loader)\n",
        "  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q11xA2sPvMD2",
        "outputId": "7e87d8ac-ccee-4184-9611-cf777a54a78f"
      },
      "outputs": [],
      "source": [
        "tabularmodel.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0F75COT0rCs",
        "outputId": "cf8ab3b3-8ba3-4549-c40c-e58d8852b05c"
      },
      "outputs": [],
      "source": [
        "nn_predictions = []\n",
        "nn_labels = []\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in val_loader:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device).view(-1,1)\n",
        "    outputs = tabularmodel(batch_features)\n",
        "    nn_predictions.extend(outputs.cpu().numpy().flatten())\n",
        "    nn_labels.extend(batch_labels.cpu().numpy().flatten())\n",
        "\n",
        "nn_predictions = np.array(nn_predictions)\n",
        "nn_labels = np.array(nn_labels)\n",
        "print(nn_predictions.shape, nn_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXc3qPrK2bqU",
        "outputId": "676eac30-13cc-4155-f241-26a05deb0a03"
      },
      "outputs": [],
      "source": [
        "r2 = r2_score(nn_labels, nn_predictions)\n",
        "rmse = np.sqrt(mean_squared_error(nn_labels, nn_predictions))\n",
        "\n",
        "print(f\"R2: {r2}, RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nn_predictions = []\n",
        "nn_labels = []\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device).view(-1,1)\n",
        "    outputs = tabularmodel(batch_features)\n",
        "    nn_predictions.extend(outputs.cpu().numpy().flatten())\n",
        "    nn_labels.extend(batch_labels.cpu().numpy().flatten())\n",
        "\n",
        "nn_predictions = np.array(nn_predictions)\n",
        "nn_labels = np.array(nn_labels)\n",
        "r2 = r2_score(nn_labels, nn_predictions)\n",
        "rmse = np.sqrt(mean_squared_error(nn_labels, nn_predictions))\n",
        "\n",
        "print(f\"train R2: {r2}, RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcAKs750Dg07"
      },
      "source": [
        "The tabular neural network demonstrated the ability to learn non-linear relationships from structured housing features but did not outperform tree-based models such as XGBoost on tabular data alone. Performance variations across runs highlighted the sensitivity of neural networks to training dynamics and initialization, reinforcing the importance of careful execution and evaluation.\n",
        "\n",
        "Incorporating Batch Normalization stabilized neural network training and produced consistent performance (R² ≈ 0.84), confirming the tabular neural network’s role as a representation learner rather than a standalone competitor to tree-based models.\n",
        "\n",
        "Despite this, the tabular neural network provides a learned feature representation that is well-suited for integration with visual features. In the next stage, this representation is combined with satellite imagery through a multimodal architecture to evaluate whether environmental context can further improve house price prediction.\n",
        "\n",
        "Also , it doesn't overfit the data as seen from the train R2 and RMSE atleast not as much as XGBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQv943TQDkcA"
      },
      "source": [
        "## Third Model: Multimodal Neural Network (Tabular + Satellite Imagery)\n",
        "\n",
        "- We now move to the combined (multimodal) model. While the tabular-only model—particularly XGBoost—already achieves strong performance, this stage evaluates whether incorporating satellite imagery provides additional predictive value.\n",
        "\n",
        "- To achieve this, satellite images are first processed using a pretrained Inception v3 model acting as a fixed feature extractor, generating 2048-dimensional image embeddings. These visual features are then fused with scaled structured housing attributes through a custom neural network architecture. The fusion model consists of separate branch networks for image and tabular data, which are concatenated and passed through fully connected layers to predict house prices. This multimodal deep learning approach leverages both visual context from satellite imagery and traditional housing attributes for price prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o_9AcndQALY"
      },
      "source": [
        "### Multimodal Data Preparation\n",
        "\n",
        "- Before training the combined model, we first need to bring everything together. For each house, we pair its satellite image with the corresponding tabular features and target price. This allows the model to learn from both visual surroundings and traditional housing attributes at the same time.\n",
        "\n",
        "- For properties without available satellite imagery, a neutral image tensor was used, allowing the model to fall back on tabular features without discarding samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "32KTiaf5LP-b"
      },
      "outputs": [],
      "source": [
        "#Just for getting image features vector once\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = models.inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
        "        self.feature_extractor.aux_logits = False\n",
        "        self.feature_extractor.fc = nn.Identity()  # output: 2048\n",
        "\n",
        "        for param in self.feature_extractor.parameters():\n",
        "          param.requires_grad = False\n",
        "        self.feature_extractor.eval() #evaluation mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.feature_extractor(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0RZM1hTfG9i"
      },
      "outputs": [],
      "source": [
        "IMAGE_DIR = \"C:\\\\Users\\\\Aashit\\\\Downloads\\\\satellite_images\\\\train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ5BQ6XtS-PO"
      },
      "outputs": [],
      "source": [
        "class MultimodalDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, tabular_cols, label_col, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.tabular_cols = tabular_cols\n",
        "        self.label_col = label_col\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # tabular_features\n",
        "        tabular = torch.from_numpy(row[self.tabular_cols].to_numpy().astype(\"float32\"))\n",
        "\n",
        "        # labels\n",
        "        label = torch.tensor(row[self.label_col],dtype=torch.float32)\n",
        "\n",
        "        # image\n",
        "        image_id = row[\"id\"]\n",
        "        image_path = os.path.join(self.image_dir, f\"{image_id}.png\")\n",
        "        image_found = True\n",
        "\n",
        "        if os.path.exists(image_path):\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "        else:\n",
        "            # Missing = zero (very low)\n",
        "            image_found = False\n",
        "            image = torch.zeros(3, 299, 299)\n",
        "\n",
        "        return image, image_found, tabular, label \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB0StPoCWIcD"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),      # match Inception\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "# ImageNet mean & std used to normalizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Must run this everytime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h87CpYrqb-j3"
      },
      "outputs": [],
      "source": [
        "\n",
        "tabular_cols = [\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\n",
        "                \"condition\",\"grade\",\"sqft_basement\",\"house_age\",\"was_renovated\",\"sqft_living15\",\n",
        "                \"sqft_lot15\",\"zip_tier\"]\n",
        "label_col = \"price_log\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90uoRE0stxaD"
      },
      "source": [
        "### STARTING THE EXTRACTOR MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B0jMTZVA7Jst",
        "outputId": "bad8005e-6cda-4f9e-8bde-9df2650abc61"
      },
      "outputs": [],
      "source": [
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "print(f\"IMAGE_DIR exists: {os.path.exists(IMAGE_DIR)}\")\n",
        "print(f\"ImageEncoder: {ImageEncoder}\")\n",
        "print(f\"MultimodalDataset: {MultimodalDataset}\")\n",
        "print(f\"image_transform: {image_transform}\")\n",
        "# to check if everything is available or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_dataset = MultimodalDataset(\n",
        "    df=df,\n",
        "    image_dir=IMAGE_DIR,\n",
        "    tabular_cols=tabular_cols,\n",
        "    label_col=label_col,\n",
        "    transform=image_transform\n",
        ")\n",
        "sample_image, sample_found, sample_tabular, sample_label = full_dataset[0]\n",
        "\n",
        "print(\"Image shape:\", sample_image.shape)\n",
        "print(\"Image min/max:\", sample_image.min().item(), sample_image.max().item())\n",
        "print(\"Is all zeros?\", torch.all(sample_image == 0).item())\n",
        "\n",
        "# Checking a few more\n",
        "zero_count = 0\n",
        "for i in range(10):\n",
        "    img, found, tab, label = full_dataset[i]\n",
        "    if torch.all(img == 0):\n",
        "        zero_count += 1\n",
        "\n",
        "print(f\"\\nZero images in first 10: {zero_count}/10\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(device)\n",
        "image_encoder = ImageEncoder().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "JdP0TGlMptk-",
        "outputId": "16776fe6-1392-4ec1-aabc-7017e879ae42"
      },
      "outputs": [],
      "source": [
        "image_features_list = []\n",
        "# ONLY NEED TO RUN THIS ONCE \n",
        "# Using DataLoader for speed with GPU\n",
        "loader = DataLoader(full_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "image_encoder.eval()\n",
        "with torch.no_grad():\n",
        "    for images, found, _, _ in tqdm(loader):\n",
        "        images = images.to(device)\n",
        "        \n",
        "        # 1. Pass through Inception\n",
        "        features = image_encoder(images) # (Batch, 2048)\n",
        "        \n",
        "        # 2. Use the 'found' flag to make zero\n",
        "        # Move 'found' to GPU and reshape\n",
        "        mask = found.to(device).view(-1, 1).float() \n",
        "        features = features * mask \n",
        "        \n",
        "        image_features_list.append(features.cpu().numpy())\n",
        "\n",
        "# saving\n",
        "image_features = np.concatenate(image_features_list, axis=0)\n",
        "np.save('image_features.npy', image_features)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### After getting image features , only need to run from this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "image_features = np.load('image_features.npy')\n",
        "print(f\"Loaded image features: {image_features.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tabular_data = df[tabular_cols].values\n",
        "labels = df[label_col].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "class FusionModel(nn.Module):\n",
        "    def __init__(self, img_dim, tabular_dim):\n",
        "        super().__init__()\n",
        "        self.image_branch = nn.Sequential(\n",
        "            nn.BatchNorm1d(img_dim), \n",
        "            nn.Linear(img_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5), #best at 0.5\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.tabular_branch = nn.Sequential(\n",
        "            nn.Linear(tabular_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Fusion layers\n",
        "        self.fusionlayers = nn.Sequential(\n",
        "            nn.Linear(64 + 128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)  # Single value output \n",
        "        )\n",
        "    \n",
        "    def forward(self, img_features, tab_features):\n",
        "        img_encoded = self.image_branch(img_features)\n",
        "        tab_encoded = self.tabular_branch(tab_features)\n",
        "        combined = torch.cat([img_encoded, tab_encoded], dim=1)\n",
        "        return self.fusionlayers(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checking if image features need scaling or not  \n",
        "print(f\"Min: {image_features.min()}\")\n",
        "print(f\"Max: {image_features.max()}\")\n",
        "print(f\"Mean: {image_features.mean()}\")\n",
        "print(f\"Std: {image_features.std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- bookmark, everything fine till here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "indices = np.arange(len(labels))\n",
        "train_idx, val_idx = train_test_split(indices, test_size=0.15, random_state=42)\n",
        "\n",
        "X_train_img = image_features[train_idx]\n",
        "X_val_img = image_features[val_idx]\n",
        "\n",
        "X_train_tab_raw = tabular_data[train_idx]\n",
        "X_val_tab_raw = tabular_data[val_idx]\n",
        "\n",
        "y_train = labels[train_idx]\n",
        "y_val = labels[val_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#scaling all the tabular data features\n",
        "scaler = StandardScaler()\n",
        "X_train_tab = scaler.fit_transform(X_train_tab_raw)\n",
        "X_val_tab = scaler.transform(X_val_tab_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, img_features, tab_features, labels):\n",
        "        self.img_features = torch.FloatTensor(img_features)\n",
        "        self.tab_features = torch.FloatTensor(tab_features)\n",
        "        self.labels = torch.FloatTensor(labels).view(-1,1)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.img_features[idx], self.tab_features[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datasets and DataLoaders\n",
        "\n",
        "train_ds = FusionDataset(X_train_img, X_train_tab, y_train)\n",
        "val_ds = FusionDataset(X_val_img, X_val_tab, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FusionModel training (only need to do to check performance not main training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "fusion_model = FusionModel(img_dim=(X_train_img.shape[1]) , tabular_dim = (X_train_tab.shape[1])).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer_fusion = optim.Adam(fusion_model.parameters(), lr=1e-3, weight_decay=1e-4, betas=(0.9, 0.999)) # best at lr=1e-3 , wd = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    fusion_model.train()\n",
        "    total_epoch_loss = 0\n",
        "    \n",
        "    for batch_img, batch_tab, batch_labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "        batch_img = batch_img.to(device)\n",
        "        batch_tab = batch_tab.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        \n",
        "        outputs = fusion_model(batch_img, batch_tab)\n",
        "        optimizer_fusion.zero_grad()\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer_fusion.step()\n",
        "        total_epoch_loss += loss.item()\n",
        "    \n",
        "    avg_train_loss = total_epoch_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}')\n",
        "\n",
        "print(\"\\nTraining complete! Now evaluation..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fusion_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fusion_predictions = []\n",
        "fusion_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_img, batch_tab, batch_labels in train_loader:\n",
        "        batch_img = batch_img.to(device)\n",
        "        batch_tab = batch_tab.to(device)\n",
        "        \n",
        "        outputs = fusion_model(batch_img, batch_tab)\n",
        "        fusion_predictions.extend(outputs.cpu().numpy().flatten())\n",
        "        fusion_labels.extend(batch_labels.numpy())\n",
        "\n",
        "fusion_predictions = np.array(fusion_predictions)\n",
        "fusion_labels = np.array(fusion_labels)\n",
        "\n",
        "# Metrics\n",
        "r2 = r2_score(fusion_labels, fusion_predictions)\n",
        "rmse = np.sqrt(mean_squared_error(fusion_labels, fusion_predictions))\n",
        "\n",
        "print(f\"Train R2:\")\n",
        "print(f\"R² Score: {r2}\")\n",
        "print(f\"RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fusion_predictions = []\n",
        "fusion_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_img, batch_tab, batch_labels in val_loader:\n",
        "        batch_img = batch_img.to(device)\n",
        "        batch_tab = batch_tab.to(device)\n",
        "        \n",
        "        outputs = fusion_model(batch_img, batch_tab)\n",
        "        fusion_predictions.extend(outputs.cpu().numpy().flatten())\n",
        "        fusion_labels.extend(batch_labels.numpy())\n",
        "\n",
        "fusion_predictions = np.array(fusion_predictions)\n",
        "fusion_labels = np.array(fusion_labels)\n",
        "\n",
        "# Metrics\n",
        "r2 = r2_score(fusion_labels, fusion_predictions)\n",
        "rmse = np.sqrt(mean_squared_error(fusion_labels, fusion_predictions))\n",
        "\n",
        "print(f\"TEST RESULTS:\")\n",
        "print(f\"R² Score: {r2}\")\n",
        "print(f\"RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Findings:\n",
        "\n",
        "1.  Best model: XGBoost (Test R2: 0.8560)\n",
        "2. Multimodal achieved Test R2: 0.8516 (competitive but didn't beat XGBoost)\n",
        "3. Gap between train/test is smallest for Multimodal (0.038), showing good generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Model Training on Full Dataset\n",
        "\n",
        "Training the best performing Multimodal model on the complete training dataset (no train/val split) to maximize available data for test predictions.\n",
        "\n",
        "**Model:** Multimodal Fusion (Tabular + Satellite Images)\n",
        "**Architecture:** \n",
        "- Image Branch: Inception features (2048) → 512 → 128\n",
        "- Tabular Branch: Features → 128 → 64\n",
        "- Fusion Layer: Combined features → 128 → 64 → 1\n",
        "\n",
        "**Configuration:**\n",
        "- Optimizer: Adam (lr=0.001, weight_decay=1e-4)\n",
        "- Batch Size: 64\n",
        "- Epochs: 60 (50 for 85% so 60 for complete training)\n",
        "- Loss: MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FusionModel(nn.Module):\n",
        "    def __init__(self, img_dim, tabular_dim):\n",
        "        super().__init__()\n",
        "        self.image_branch = nn.Sequential(\n",
        "            nn.BatchNorm1d(img_dim), \n",
        "            nn.Linear(img_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5), #best at 0.5\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.tabular_branch = nn.Sequential(\n",
        "            nn.Linear(tabular_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Fusion layers\n",
        "        self.fusionlayers = nn.Sequential(\n",
        "            nn.Linear(64 + 128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)  # Single value output \n",
        "        )\n",
        "    \n",
        "    def forward(self, img_features, tab_features):\n",
        "        img_encoded = self.image_branch(img_features)\n",
        "        tab_encoded = self.tabular_branch(tab_features)\n",
        "        combined = torch.cat([img_encoded, tab_encoded], dim=1)\n",
        "        return self.fusionlayers(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, img_features, tab_features, labels):\n",
        "        self.img_features = torch.FloatTensor(img_features)\n",
        "        self.tab_features = torch.FloatTensor(tab_features)\n",
        "        self.labels = torch.FloatTensor(labels).view(-1,1)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.img_features[idx], self.tab_features[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final = pd.read_csv('train_preprocessed.csv')\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(df_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_features_final = np.load('image_features.npy')\n",
        "print(f\"Loaded image features: {image_features_final.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tabular_cols = [\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\n",
        "                \"condition\",\"grade\",\"sqft_basement\",\"house_age\",\"was_renovated\",\"sqft_living15\",\n",
        "                \"sqft_lot15\",\"zip_tier\"]\n",
        "label_col = \"price_log\"\n",
        "tabular_data_final = df_final[tabular_cols].values\n",
        "labels_final = df_final[label_col].values\n",
        "#scaling tabular data \n",
        "\n",
        "scaler = StandardScaler()\n",
        "tabular_data_final = scaler.fit_transform(tabular_data_final)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#saving scaler for test (only once)\n",
        "import pickle\n",
        "with open('tabular_scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datasets and DataLoaders\n",
        "finaltraining_dataset = FusionDataset(img_features = image_features_final, \n",
        "                                      tab_features=tabular_data_final, labels=labels_final)\n",
        "finaltraining_loader = DataLoader(finaltraining_dataset, batch_size=64, shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checking dataset and dataloader sizes\n",
        "print(f\"Full dataset size: {len(finaltraining_dataset)}\")\n",
        "print(f\"Number of batches: {len(finaltraining_loader)}\")\n",
        "print(f\"Expected batches: {len(finaltraining_dataset) / 64}\")\n",
        "print(f\"X shape: {tabular_data_final.shape}\")\n",
        "print(f\"y shape: {labels_final.shape}\")\n",
        "print(f\"Image features shape: {image_features_final.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "final_model = FusionModel(img_dim=(image_features_final.shape[1]) , tabular_dim = (tabular_data_final.shape[1])).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer_fusion = optim.Adam(final_model.parameters(), lr=1e-3, weight_decay=1e-4, betas=(0.9, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MAIN TRAINING LOOP "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "epochs = 60\n",
        "train_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    final_model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for img_batch, tab_batch, target_batch in tqdm(finaltraining_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "        img_batch = img_batch.to(device)\n",
        "        tab_batch = tab_batch.to(device)\n",
        "        target_batch = target_batch.to(device)\n",
        "        \n",
        "        optimizer_fusion.zero_grad()\n",
        "        outputs = final_model(img_batch, tab_batch)\n",
        "        loss = criterion(outputs, target_batch)\n",
        "        loss.backward()\n",
        "        optimizer_fusion.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    avg_loss = epoch_loss / len(finaltraining_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "    print(f\"Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#plotting training losses to see changes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(11, epochs+1), train_losses[10:], 'b-', linewidth=1)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create non-shuffled loader for evaluation\n",
        "eval_loader = DataLoader(finaltraining_dataset, batch_size=64, shuffle=False)\n",
        "final_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#evaluating on training once \n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_batch, tab_batch, target_batch in eval_loader:\n",
        "        img_batch = img_batch.to(device)\n",
        "        tab_batch = tab_batch.to(device)\n",
        "        \n",
        "        outputs = final_model(img_batch, tab_batch)\n",
        "        all_preds.append(outputs.cpu().numpy())\n",
        "        all_labels.append(target_batch.cpu().numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "train_r2 = r2_score(all_labels, all_preds)\n",
        "train_rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
        "\n",
        "print(f\"Final Training R2: {train_r2}\")\n",
        "print(f\"Final Training RMSE: {train_rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "torch.save(final_model.state_dict(), 'final_fusion_model.pt')\n",
        "print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Set Predictions\n",
        "\n",
        "Generating predictions on the test dataset using the final trained multimodal fusion model.\n",
        "\n",
        "**Steps:**\n",
        "1. Load preprocessed test tabular data\n",
        "2. Extract image features from test satellite images using pretrained Inception v3\n",
        "3. Scale test features using saved scaler\n",
        "4. Generate predictions using trained model\n",
        "5. Create submission CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Loading preprocessed test tabular data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(\"C:\\\\Users\\\\Aashit\\\\OneDrive\\\\Desktop\\\\Coding_stuff\\\\PROJECTS\\\\real-estate-multimodal\\\\test_preprocessed.csv\")\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tabular_cols = [\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\n",
        "                \"condition\",\"grade\",\"sqft_basement\",\"house_age\",\"was_renovated\",\"sqft_living15\",\n",
        "                \"sqft_lot15\",\"zip_tier\"]\n",
        "test_tabular = test_df[tabular_cols].values\n",
        "print(f\"test_tabular : {test_tabular.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 EXTRACT IMAGE FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Just for getting image features vector once\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = models.inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
        "        self.feature_extractor.aux_logits = False\n",
        "        self.feature_extractor.fc = nn.Identity()  # output: 2048\n",
        "\n",
        "        for param in self.feature_extractor.parameters():\n",
        "          param.requires_grad = False\n",
        "        self.feature_extractor.eval() #evaluation mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.feature_extractor(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_IMAGE_DIR = \"C:\\\\Users\\\\Aashit\\\\Downloads\\\\satellite_images\\\\test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TestMultimodalDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, tabular_cols, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.tabular_cols = tabular_cols\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        \n",
        "        # Image\n",
        "        image_id = row[\"id\"]\n",
        "        image_path = os.path.join(self.image_dir, f\"{image_id}.png\")\n",
        "        image_found = True\n",
        "        \n",
        "        if os.path.exists(image_path):\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "        else:\n",
        "            image_found = False\n",
        "            image = torch.zeros(3, 299, 299) #zeros(since only few are missing)\n",
        "        \n",
        "        return image, image_found  # No tabular or label needed for feature extraction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),      # match Inception\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "# ImageNet mean & std used to normalizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"DataFrame shape: {test_df.shape}\")\n",
        "print(f\"TEST_IMAGE_DIR exists: {os.path.exists(TEST_IMAGE_DIR)}\")\n",
        "print(f\"TestMultimodalDataset: {TestMultimodalDataset}\")\n",
        "print(f\"ImageEncoder: {ImageEncoder}\")\n",
        "print(f\"image_transform: {image_transform}\")\n",
        "# to check if everything is available or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = TestMultimodalDataset(\n",
        "    df=test_df,\n",
        "    image_dir=TEST_IMAGE_DIR,\n",
        "    tabular_cols=tabular_cols,\n",
        "    transform=image_transform\n",
        ")\n",
        "sample_image, sample_found = test_dataset[0]\n",
        "\n",
        "print(\"Image shape:\", sample_image.shape)\n",
        "print(\"Image min/max:\", sample_image.min().item(), sample_image.max().item())\n",
        "print(\"Is all zeros?\", torch.all(sample_image == 0).item())\n",
        "\n",
        "# Checking a few more\n",
        "zero_count = 0\n",
        "for i in range(10):\n",
        "    img, found = test_dataset[i]\n",
        "    if torch.all(img == 0):\n",
        "        zero_count += 1\n",
        "\n",
        "print(f\"\\n Zero images in first 10: {zero_count}/10\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(device)\n",
        "image_encoder = ImageEncoder().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_features_list = []\n",
        "# ONLY NEED TO RUN THIS ONCE \n",
        "# Using DataLoader for speed with your own GPU\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "image_encoder.eval()\n",
        "with torch.no_grad():\n",
        "    for images, found in tqdm(test_loader):\n",
        "        images = images.to(device)\n",
        "        \n",
        "        # 1. Pass through Inception\n",
        "        features = image_encoder(images) # (Batch, 2048)\n",
        "        \n",
        "        # 2. Using the 'found' flag to zero out missing entries\n",
        "        # Move 'found' to GPU and reshape\n",
        "        mask = found.to(device).view(-1, 1).float() \n",
        "        features = features * mask \n",
        "        \n",
        "        image_features_list.append(features.cpu().numpy())\n",
        "\n",
        "\n",
        "test_image_features = np.concatenate(image_features_list, axis=0)\n",
        "np.save('test_image_features.npy', test_image_features)\n",
        "print(f\"Saved: {test_image_features.shape}\")\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Loading test image features "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_features_test = np.load('test_image_features.npy')\n",
        "print(f\"Loaded image features: {image_features_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 VERIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Finding indices in the array where the features are all zeros\n",
        "zero_feature_indices = np.where(~image_features_test.any(axis=1))[0]\n",
        "\n",
        "# Finding indices in your dataframe where images were missing\n",
        "missing_image_indices = test_df[test_df['id'].apply(\n",
        "    lambda x: not os.path.exists(os.path.join(TEST_IMAGE_DIR, f\"{x}.png\"))\n",
        ")].index.tolist()\n",
        "\n",
        "\n",
        "if set(zero_feature_indices) == set(missing_image_indices):\n",
        "    print(\"Alignment Verified: Features match CSV rows perfectly.\")\n",
        "else:\n",
        "    print(\"Alignment Error: Features and CSV rows are out of sync!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. SCALE TEST FEATURES USING TABULAR_SCALAR.PKL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading saved scaler and transform test data\n",
        "import pickle\n",
        "with open('tabular_scaler.pkl', 'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "test_tabular_scaled = scaler.transform(test_tabular)\n",
        "print(f\"Scaled shape: {test_tabular_scaled.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Generate PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test dataset (using numpy arrays directly)\n",
        "class TestPredictionDataset(Dataset):\n",
        "    def __init__(self, img_features, tab_features):\n",
        "        self.img_features = torch.FloatTensor(img_features)\n",
        "        self.tab_features = torch.FloatTensor(tab_features)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img_features)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.img_features[idx], self.tab_features[idx]\n",
        "\n",
        "test_pred_dataset = TestPredictionDataset(image_features_test, test_tabular_scaled)\n",
        "test_pred_loader = DataLoader(test_pred_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"Test dataset size: {len(test_pred_dataset)}\")\n",
        "print(f\"Number of batches: {len(test_pred_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FusionModel(nn.Module):\n",
        "    def __init__(self, img_dim, tabular_dim):\n",
        "        super().__init__()\n",
        "        self.image_branch = nn.Sequential(\n",
        "            nn.BatchNorm1d(img_dim), \n",
        "            nn.Linear(img_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5), #best at 0.5\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        self.tabular_branch = nn.Sequential(\n",
        "            nn.Linear(tabular_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Fusion layers\n",
        "        self.fusionlayers = nn.Sequential(\n",
        "            nn.Linear(64 + 128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)  # Single value output \n",
        "        )\n",
        "    \n",
        "    def forward(self, img_features, tab_features):\n",
        "        img_encoded = self.image_branch(img_features)\n",
        "        tab_encoded = self.tabular_branch(tab_features)\n",
        "        combined = torch.cat([img_encoded, tab_encoded], dim=1)\n",
        "        return self.fusionlayers(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading trained model\n",
        "final_model = FusionModel(img_dim=image_features_test.shape[1], \n",
        "                          tabular_dim= test_tabular_scaled.shape[1]).to(device)\n",
        "final_model.load_state_dict(torch.load('final_fusion_model.pt'))\n",
        "final_model.eval()\n",
        "print(\"Model loaded and ready for prediction. \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_predictions = []\n",
        "final_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_batch, tab_batch in tqdm(test_pred_loader, desc=\"Predicting\"):\n",
        "        img_batch = img_batch.to(device)\n",
        "        tab_batch = tab_batch.to(device)\n",
        "        \n",
        "        batch_preds = final_model(img_batch, tab_batch)\n",
        "        all_predictions.append(batch_preds.cpu().numpy())\n",
        "\n",
        "test_predictions = np.concatenate(all_predictions).flatten()\n",
        "print(f\"Predictions shape: {test_predictions.shape}\")\n",
        "print(f\"Sample predictions (log scale): {test_predictions[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Creating Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# first changing log-prices back to prices\n",
        "actual_prices = np.exp(test_predictions)\n",
        "\n",
        "print(f\"Sample prices : {actual_prices[:5]}\")\n",
        "print(f\"Actual price range : {actual_prices.min():.2f} to {actual_prices.max():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating submission CSV\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'].astype(int),\n",
        "    'predicted_price': actual_prices.round(0).astype(int)\n",
        "})\n",
        "\n",
        "submission.to_csv('24322002_final.csv', index=False)\n",
        "print(f\"Total predictions: {len(submission)}\")\n",
        "submission.head(10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "x_dgrskzXGVu",
        "j3BfOU3zcpwc"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
